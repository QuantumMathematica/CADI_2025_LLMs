{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook usaremos llama 3 a través de una API (uso \"limitado\" gratuito), sin usar el llm localmente en la computadora. Es necesario crear una cuenta aquí:\n",
    "\n",
    "https://console.groq.com/login\n",
    "\n",
    "y solicitar una key:\n",
    "\n",
    "https://console.groq.com/keys\n",
    "\n",
    "Create a file named .env where you store the value of your key:\n",
    "\n",
    "GROQ_API_KEY='---'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.3.9 in ./.venv/lib/python3.9/site-packages (0.3.9)\n",
      "Requirement already satisfied: langchain-core==0.3.21 in ./.venv/lib/python3.9/site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain-ollama==0.2.0 in ./.venv/lib/python3.9/site-packages (0.2.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.9/site-packages (from langchain==0.3.9) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.9/site-packages (from langchain==0.3.9) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.9/site-packages (from langchain==0.3.9) (3.10.10)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./.venv/lib/python3.9/site-packages (from langchain==0.3.9) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./.venv/lib/python3.9/site-packages (from langchain==0.3.9) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.venv/lib/python3.9/site-packages (from langchain==0.3.9) (0.1.141)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in ./.venv/lib/python3.9/site-packages (from langchain==0.3.9) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.9/site-packages (from langchain==0.3.9) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.9/site-packages (from langchain==0.3.9) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./.venv/lib/python3.9/site-packages (from langchain==0.3.9) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.9/site-packages (from langchain-core==0.3.21) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.9/site-packages (from langchain-core==0.3.21) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.9/site-packages (from langchain-core==0.3.21) (4.12.2)\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in ./.venv/lib/python3.9/site-packages (from langchain-ollama==0.2.0) (0.3.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9) (1.17.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.21) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.9) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.9) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.9) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.9) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./.venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.9) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.3.9) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.3.9) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.3.9) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.3.9) (2024.8.30)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.9) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.9) (1.0.6)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.9) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.9) (0.14.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.9/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain==0.3.9) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.9) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install langchain==0.3.9 langchain-core==0.3.21 langchain-ollama==0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting groq\n",
      "  Downloading groq-0.15.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langchain_groq\n",
      "  Downloading langchain_groq-0.2.3-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.9/site-packages (from groq) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.9/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.9/site-packages (from groq) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.9/site-packages (from groq) (2.9.2)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.9/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in ./.venv/lib/python3.9/site-packages (from groq) (4.12.2)\n",
      "Collecting langchain-core<0.4.0,>=0.3.29 (from langchain_groq)\n",
      "  Downloading langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->groq) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain_groq) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain_groq) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain_groq) (0.1.141)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain_groq) (24.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain_groq) (9.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain_groq) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.9/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_groq) (3.10.11)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.9/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_groq) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.9/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_groq) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_groq) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_groq) (2.2.3)\n",
      "Downloading groq-0.15.0-py3-none-any.whl (109 kB)\n",
      "Downloading langchain_groq-0.2.3-py3-none-any.whl (14 kB)\n",
      "Downloading langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
      "Installing collected packages: groq, langchain-core, langchain_groq\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.21\n",
      "    Uninstalling langchain-core-0.3.21:\n",
      "      Successfully uninstalled langchain-core-0.3.21\n",
      "Successfully installed groq-0.15.0 langchain-core-0.3.29 langchain_groq-0.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install groq langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elisabetta/VisualStudioProjects/CADI_2025_LLMs/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key= os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'llama-3.1-70b-versatile'\n",
    "model_name = 'llama3-8b-8192'\n",
    "\n",
    "groq_chat = ChatGroq(\n",
    "        groq_api_key=api_key,\n",
    "        model_name=model_name,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "llm = groq_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hola!\\n\\nLa respuesta a 2+2 es... 4!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 18, 'total_tokens': 33, 'completion_time': 0.0125, 'prompt_time': 0.003538674, 'queue_time': 0.017829866, 'total_time': 0.016038674}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None}, id='run-a56c1c1c-15ec-402e-a433-47e95d8fe58e-0', usage_metadata={'input_tokens': 18, 'output_tokens': 15, 'total_tokens': 33})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages= 'Hola, cuanto es 2+2'\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola!\\n\\nLa respuesta a 2+2 es... 4!'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = StrOutputParser()\n",
    "chain = llm | parser \n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola! El color que he escogido es... Azul!\n",
      "Hola! El color que he escogido es... Azul!\n",
      "Hola! El color que he escogido es... Azul!\n",
      "Hola! El color que he escogido es... Azul!\n",
      "Hola! El color que he escogido es... Azul!\n"
     ]
    }
   ],
   "source": [
    "messages = 'Hola, escribe un color cualquiera'\n",
    "chain = llm | parser\n",
    "for i in range(5):\n",
    "    print(chain.invoke(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_chat = ChatGroq(\n",
    "        groq_api_key=api_key,\n",
    "        model_name=model_name,\n",
    "        temperature=1,\n",
    "    )\n",
    "\n",
    "llm = groq_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azul!\n",
      "Hola!\n",
      "¡Hola!\n",
      "\n",
      "El color que he escrito es... **VERDE**\n",
      "Hola! El color que he escrito es... Verde\n",
      "Hola! El color que he escogido es... ROJO!\n"
     ]
    }
   ],
   "source": [
    "messages = 'Hola, escribe un color cualquiera'\n",
    "chain = llm | parser\n",
    "for i in range(5):\n",
    "    print(chain.invoke(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"Translate the following into {language}, write only the translated word:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into italian, write only the translated word:', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = prompt_template.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dal punto di vista accademico, ha dimostrato un registro accademico eccezionale e impegno, è stata lavoratrice, perseverante e aperta a sfide. \\n\\npenso che Ana abbia un alto talento per matematica, scienza dei dati, programmazione e modellizzazione matematica, nonché abili skills per la risoluzione dei problemi.\\n\\nDal punto di vista personale, Ana mi ha impressionato per la sua grande interesse, curiosità e dedizione.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"language\": \"italian\", \"text\": \"From the academical point of view, she has shown a great academic record and involvement, she has been hardworking, perseverant, and open to challenges. I think Ana has a high aptitude for math, data science, programming, and mathematical modeling, as well as strong problem-solving skills. From the personal point of view, Ana impressed me for her great interest, curiosity, and dedication. \"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"user\", \"Tell me a joke about {topic}\")\n",
    "])\n",
    "\n",
    "chain = prompt_template | llm | parser\n",
    "chain.invoke({\"topic\": \"cats\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
